[["index.html", "A Practical Guide to Data Anonymisation Chapter 1 Introduction 1.1 How to cite and license 1.2 Acknowledgements", " A Practical Guide to Data Anonymisation Alice Nikuze, Deniece Nazareth, Minsi Li 2024-11-04 Chapter 1 Introduction In todays data-driven world, privacy concerns have become paramount. With the increasing collection of personal data in research, researchers bear the responsibility of ensuring the protection of the privacy rights of the individuals participating in their studies. In addition, the General Data Protection Regulation (GDPR) in Europe requires researchers affiliated with any institution within the European Economic Area (EEA) to protect the privacy of research participants if they handle personal data in their research. In this context, the more personal data are collected, the greater the need for data de-identification and, eventually, anonymization. This guide provides practical guidance on pseudonymizing and anonymizing personal data in research. It includes hands-on examples of various techniques for different types of research data. Although extensive techniques and examples are given, please note that this guide does not contain every issue related to pseudonymization or anonymisation. As the de-identification of your research data is often complex and a case by case solution. Please advise your privacy contact person for more information. The guide is structured as follows:  In Chapter 2, concepts and principles of data anonymisation are introduced.  In Chapter 3, the principle of data minimisation is introduced.  In Chapter 4, the concepts of data pseudonymisation and anonymisation are explained.  In Chapter 5, the pseudonymization and anonymisation techniques for different types of research data, mainly textual data, numerical data, audio and visual data and spatial data are discussed. Practical examples regarding these types of data are given.  In Chapter 6, the guide concludes with some practical considerations. 1.1 How to cite and license A Practical Guide to Data Anonymization Â© 2024 by Alice Nikuze, Deniece Nazareth, Minsi Li is licensed under CC BY 4.0. 1.2 Acknowledgements We would like to extend our sincere gratitude to dr. Qian Zhang for her invaluable contribution during the conceptualization phase of this guide. We also wish to express our sincere appreciation to Nestor De la Paz Ruiz for his contribution, whose efforts were instrumental in transforming this guide into a Gitbook. "],["personal_data.html", "Chapter 2 What is personal data?", " Chapter 2 What is personal data? The term Personal data refers to any information that enables you to identify a living person. According to the GDPR, a living person can be identified, directly or indirectly, by means of an identifier such as a name, a citizen identification number, location data, or by other information specific to the physical, physiological, genetic, mental, economic, cultural, or social identity of that living person. Direct identifiers Strong indirect identifiers Indirect identifiers Information unique to an individual can directly identify that person. Direct identifiers Information unique to an individual can directly identify that person. Strong indirect identifiers Information that can easily identify an individual, such as a rare event, uncommon disease, unique job title, or IP address. Indirect identifiers Information that, when combined with other data, can identify an individual, such as address, age, gender, occupation, location, health records, or ethnic group. It is worth noting that some identifiers are particularly considered strong indirect identifiers because they can significantly increase the risk of identifying an individual when combined with other information. Examples of strong identifiers include a date of birth, an IP address etc. For extensive overview of different types of identifiers, see Table 1. Table 1. Overview of identifiers typically processed in research Archive (2023) (Archive, F. S. S. D. (n.d.). Anonymisation and Personal Data - Finnish Social Science Data Archive (FSD). Finnish Social Science Data Archive (FSD).https://www.fsd.tuni.fi/en/services/data-management-guidelines/anonymisation-and-identifiers/) "],["minimization.html", "Chapter 3 Principle and Concepts of data minimization 3.1 Data minimization 3.2 Pseudonymisation versus Anonymisation", " Chapter 3 Principle and Concepts of data minimization 3.1 Data minimization Data minimization is a key principle of data privacy and involves limiting data collection and retention to only what is relevant, necessary, and adequate to accomplish a given purpose. In line with this principle, a researcher should only collect and retain the personal data that is required for a research study in mind. Planning carefully what kind of personal data is necessary for the research purpose. It is advised to carefully plan this early during the research design phase. For instance, you should not ask for the age of a research participant (data subject) if the age effect is not investigated in the research. Collecting aggregated information if detailed information is not necessary. For example, if the age range is sufficient for the analysis, you should not collect the actual age of the participant. Limiting open-ended questions in surveys. Answers to open-ended survey questions provided by respondents occasionally contain personal data about the respondents themselves or other people. Having many open-ended questions in your survey requires more anonymization effort after collecting the data. Instructing research participants sufficiently to avoid providing unnecessary personal data. In open-ended questions in surveys and during interviews, the participant might mention unnecessary personal information about him/herself or a third person. Adding extra instructions in the survey and reminding the participants not to mention personal data (e.g., other peoples names or addresses) before conducting the interview is well worth the effort. Instructing research participants sufficiently to avoid providing unnecessary personal data. In open-ended questions in surveys and during interviews, the participant might mention unnecessary personal information about him/herself or a third person. Adding extra instructions in the survey and reminding the participants not to mention personal data (e.g., other peoples names or addresses) before conducting the interview is well worth the effort. Adjusting the settings of the data collection tool (e.g., survey tools) to avoid collecting unnecessary personal data. Some survey tools are per default set up to collect personal data such as the location and/or IP address of the user. Always check the settings of the tool you use for data collection. Collecting only the minimum amount of personal data necessary for your research reduces the threat of data breaches and privacy violations, thereby reducing potential consequences for the research participants. When personal data are necessary and have been collected for research, research participants identities should be protected. Two techniques are used to ensure that research participants remain anonymous and untraceable during and after research- pseudonymisation and anonymization. 3.2 Pseudonymisation versus Anonymisation 3.2.1 Pseudonymisation Pseudonymisation is a de-identification process after which personal data can no longer be attributed to a specific data subject without the use of additional information. This process is also referred to as coding. It involves creating two separate files, one linking the personal data to the pseudonyms (made-up values/tokens) and another file which contains only the pseudonyms and the supplied research information. The former file is known as a key file or code list and must be kept separately from the latter file. The key file should be subjected to extra security measures (such as secured storage, password protection and encryption) to ensure that the identities of research participants are protected. 3.2.2 Anonymisation Anonymisation is another de-identification process which involves deleting direct and/or indirect identifiers from the data, such that there is no way to re-establish the link between individuals (research participants) and the research information they have supplied. In this case, there is no key file. Pseudonymization is employed to protect the identities of research participants by substituting direct identifiers with pseudonyms. This process is reversible and can still allow re-identification. In contrast, anonymisation involves deleting the identifiers, rendering re-identification impossible, even by researchers themselves. The process is irreversible. As a good practice, the details of how anonymisation was done should be clearly documented for future reference. Note that such documentation should be protected as it may facilitate re-identification of the anonymized data. Unlike pseudonymized data, anonymized data does not fall under GDPR. However,please note that, fully anonymized data can be difficult to achieve Additionally, full anonymization is sometimes not desirable, especially in qualitative research, as you may lose the context or usability of the data. Practical Consideration  Anonymization affect the utility of the data, where in some case the data become useless for reuse. Therefore, it should be clearly documented in the metadata of the dataset where anonymization has been performed.  Create a key file(a de-anonymization key) of all removals, replacements, aggregations or generalisations made. Store such a key file securely and separately from data files(refereces needed). Icons made by Freepik from www.flaticon.com "],["techniques.html", "Chapter 4 Research Data Types and Pseudonymisation and Anonymisation Techniques 4.1 Is that possible to single out, link, or infer individual from the dataset? 4.2 Any remaining information in the dataset still sensitive, or unique? 4.3 Any additional information and techniques for re-identification.", " Chapter 4 Research Data Types and Pseudonymisation and Anonymisation Techniques Following the concepts and principles of data anonymization, before diving into the technique of anonymization, this section will focus on practical steps to plan and assess data anonymization. To see which techniques are most suitable for your data, it is helpful first to see what you want to anonymize. Based on the approach of Personal Data Protection Commission of Singapore, you can follow these steps to identify your data. Anonymized data refers to data after removing personal information to avoid the possibility of re-identify one individual from the data. Anonymization is not an absolute value, but a spectrum. In the following scenarios, data is not considered as anonymized data: Raw data containing personal data still exist. Key or other information that can be used to re-identify individuals in the dataset still exist. Anonymizing textual data, such as interview transcripts, is challenging to fully achieve. Certain personal details are closely tied to data utility and, for research purposes, may not be removed. For instance, when investigating stakeholders views on policy, data utility of the textual data is related to the personal information of the interviewee, such as professional background, experience. Furthermore, even when researchers remove as much personal information as possible, there remains a risk of re-identification through singling out, inference, or linking with other information, techniques, or external datasets. If such data is shared publicly, individuals familiar with the data subjects may still be able to re-identify them. When anonymizing data, its essential to balance the protection of data subjects privacy with the utility of the data. Data utility refers to the datas ability to address research questions effectively. For example, in a study on student performance and family socioeconomic status, identifiers like student names, gender, and age should be removed to protect privacy, while information on grades and family economic conditions should be retained, as these are critical for addressing the research objectives. To assess the completeness of anonymization, the following questions are relevant: 4.1 Is that possible to single out, link, or infer individual from the dataset? Single out refers to isolate someone from the dataset. Link refers to combine information within and outside of the dataset to identify an individual. Inference refers to infer, guess, or predict details about an individual. For multimedia data, three categories should be taken care: Biometric identifiers that are distinctive, measurable, generally unique and permanent personal characteristics used to identify individuals. This includes physiological biometrics (face, iris, ear, fingerprint) and behavioral biometrics (voice, gait, gesture, lipmotion, and typing style); Soft biometrics of some vague physical, behavioral or adhered human characteristic that is not necessarily permanent or distinctive (height, weight, eye color, silhouette, age, gender, race, moles, tattoos, birthmarks, and scars); Non-biometric identifiers including text context, speech context, specific social-political and environmental context, dressing style, and hairstyle. https://nvlpubs.nist.gov/nistpubs/ir/2015/nist.ir.8053.pdf Chapter 2: How do we ensure anonymisation is effective? 4.2 Any remaining information in the dataset still sensitive, or unique? 4.2.1 Uniqueness To measure the uniqueness of a data point, count the data points within each category formed by distinct combinations of two attributes in the dataset. If there is only one data point in a category, that value is unique, indicating a high risk of re-identification. It is ideal to strive for at least 3 data points in one distinct combination of any two remaining (in)direct identifiers (https://nvlpubs.nist.gov/nistpubs/ir/2015/nist.ir.8053.pdf). However, it is necessary to distinguish between uniqueness in the sample and uniqueness in the population. Risk of identification is higher when the uniqueness in the population. However, some uniqueness in a sample is equivalent to the uniqueness in the population. For example, a patient with rare disease is unique in the sample and in the neighbourhood; a surgeon in a hospital and in the city. 4.2.2 Sensitivity Whether the information can put individuals or certain groups into vulnerable place, such as physical and mental harms, revelation of financial, political, religion, sexual orientation, or embarrassment. 4.3 Any additional information and techniques for re-identification. To assess the possibility of reasonable likely to re-identify individuals from anonymized data, it is relevant to consider the following questions:  Any external information exist to identify individuals, such as other datasets, personal knowledge.  Techniques that can be reverse the anonymization or link data.  Motivated intruders. Someone who is competent, have appropriate resources, and investigative techniques to re-identify individuals in the dataset. The motivated intruders could be investigative journalists, estranged partners, stalkers, industrial spies, or acquaintances of data subjects.  The scope of releasing data: a defined group or public domain The cost of re-identification: someone with access to significant specialist expertise, analytical power, or prior knowledge can re-identify individuals, the cost is higher. The pseudonymisation and anonymisation techniques vary depending on the types and nature of the data. This guide will discuss the techniques for the following types of research data: textual data, numerical data, audio and visual data, and geospatial data. Direct identifiers Strong indirect identifiers Indirect identifiers Information unique to an individual can directly identify that person. "],["textual-data.html", "Chapter 5 Textual data 5.1 Generalisation: Replace or aggregate 5.2 Distort", " Chapter 5 Textual data Textual data refers to any text-based content such as transcripts of interviews, workshops and focus group discussions, open-ended questions in surveys, observational notes, meeting notes, etc. This data type can be de-identified by generalizing the identifying information, distorting or deleting the identifiers such as research participants names, gender, age, income, places and institutions names, addresses (physical location, email and IP), telephone numbers and any other sensitive information. The following techniques are commonly used to pseudonymize or anonymize textual data. 5.1 Generalisation: Replace or aggregate Generalization involves reducing detailed information or the precision of the information in a way that potentially disclosive information is replaced or aggregated. This approach mainly involves replacing or aggregating identifiers with vague descriptors, such as replacing the actual names of individuals with aliases or with other aggregated information. 5.2 Distort In certain cases, instead of generalizing crucial information needed to understand the context and content, its possible to distort the information by changing other identifiers. For example, if you have interviewed someone who participated in a high-level sports competition, and if that information is of importance in research, then you may change other values. You could change the years when the competition took place, the region (place, country) or even the gender of the person if this is not crucial information. 5.2.1 Suppression: Delete If the identifying information cannot be replaced or generalized, the entire variable or text may need to be deleted and explicitly marked as such by using [brackets]. 5.2.2 Masking Masking textual data involves replacing letters or symbols (punctuation) in identifying information entirely or partially with a special symbol (such as * or x). It is commonly used for identifiers such as email addresses, names of locations, etc. This technique is more suitable for structured tabular data, meaning that data is stored in the form of columns and rows. For more inspiration on how to anonymize textual data, please consult this illustrative example provided by CESSDA, which demonstrates the process of anonymizing an interview script. Tools Masking can be performed through manipulation in character data and natural language processing in R or Python. Some examples can be found in the Mask attributes section under Numerical Data in this guide. "],["numerical-data.html", "Chapter 6 Numerical data 6.1 Suppression 6.2 Swapping 6.3 Masking 6.4 Generalisation", " Chapter 6 Numerical data Numerical data is data in the form of numbers and is often displayed in a table with rows and columns. The techniques commonly used to anonymise numerical data include: 6.1 Suppression Suppression involves deleting the identifying information from the data. Some attributes (variables) or records (observations) can be removed in certain cases to make the identifier is not unique anymore. 6.2 Swapping This technique is also known as shuffling and permutation. When each data subjects has attributes which are stored in the columns in a spreadsheet, swap the attributes among two random data subjects till exhaust all data subjects in the dataset. In this way, the distribution of attributes would not be changes, while each data subjects attributes are changed. For example, when collecting each data subjects email address and IP address, swap each subjects IP address would reduce the chances of identifying one data subject with their both email address and IP address. 6.3 Masking The same way letters in textual data are replaced, numbers can be entirely or partially replaced with a special symbol (such as * or x). See the table below for examples. 6.4 Generalisation Generalisation techniques reduce the granularity of the attributes/records in the data. It can be performed by Categorising personal identifiers.* For example, age is replaced by an age category or range. Top and bottom coding of the upper or lower ranges. Very high and low values are grouped into categories to minimize identifiability due to outliers. For example, age records above a certain upper and lower limit are classified as groups to avoid recognition of exceptionally older or younger individuals while preserving actual ages for the rest of the population within the wider group researched. A top code of  X or more could be applied to avoid identifying older subjects. Collapsing and/or combining variables. Merging data recorded in two or more variables into a single category. This is particularly useful if the initial data collection creates several categories with very few subjects in each. Perturbation can be used where small changes in value are acceptable. This technique involves rounding, adding noise, or replacing real values with simulation values. It should not be used when data accuracy is critical. The following section demonstrates examples of rounding and adding noise techniques with practical examples. Rounding It returns a number rounded to a base number to prevent exact matching with external data sources (https://sdcpractice.readthedocs.io/en/latest/anon_methods.html#special-case-census-data). It can be used to deal with data like age, height, weight, or house number. Examples of rounding is demonstrated with tools, Excel, R, or Python. Noise addition This technique adds or subtracts the original values with a random number. Larger random numbers result in higher levels of noise. Note that the results of noise addition are irreversible because each modification introduces randomness to the original values. This technique can be used to few values, such as outliers, or to entire dataset. When handling data with continuous value, the distribution of continuous data should be preserved to maintain more information in the datasets. Examples can be found in the table below. "],["audio-visual-data.html", "Chapter 7 Audio-Visual data 7.1 Voice transformation/distortion 7.2 Blurring, pixelation or obscuring 7.3 Mute or bleep out the identifying information", " Chapter 7 Audio-Visual data Audio-visual data includes various forms of multimedia content, such as videos, movies, and audio recordings, including voices and visual components. In research, these forms of data capture interviews, workshops and any other form of communication with research participants involving their voices and/or images. Anonymizing these types of data involves modifying the audio, video or images, which will be introduced in this section. Keep in mind that these techniques can be time-consuming or expensive to use. Icons made by Icon mania from www.flaticon.com 7.1 Voice transformation/distortion This technique involves disguising voices such as altering the pitch in a recording. Keep in mind that transforming or distorting the voice can reduce the usefulness of the data. Therefore, the decision of modifying sounds should be made based on your research objectives. 7.2 Blurring, pixelation or obscuring Blurring by pixelating specific regions of a video image or a picture, such as faces, can effectively anonymize individuals. This technique involves reducing the level of detail in those areas, making it harder to identify the person. In addition, you can also obscure the face of a person. See Image XX for an example of pixelating a face. Simpel distortion of the audio or imagery can only prevent idetnfication based on the speakers voice or iamge but it cannot remove other idetnfiying information that might exist in the recoding, such as speaking patterns or the mentioned personal information. 7.3 Mute or bleep out the identifying information In audio or video recordings, you can also mute or bleep out identifying information to anonymize the audio-visual data. For example, you can mute or bleep out identifiers such as names, places or other information. Please see image XX below where the personal name has been muted in the audio recording. Software for audio-visual data  For audio data, audio editing software such as Audacity can be used to transform or distort the voice or bleep out personal information.  Different video editing software such as Adobe Premiere can be used to blur or pixelate video recordings or transform, distort or bleep out information in the audio recording.  For images, image editor tools such as Photoshop and Paint can be used to blur, pixelate or obscure faces or personal information in pictures and images. "],["geospatial-data.html", "Chapter 8 Geospatial data 8.1 Spatial generalisation 8.2 Attribute anonymisation", " Chapter 8 Geospatial data Geospatial data refers to data that is associated with specific geographic locations. Spatial data are used in research for analysis, visualization, and understanding of relationships and patterns within a geographic context. This section presents some of the techniques used to de-identify spatial data. The existing anonymisation techniques fall into two categories of generalization and randomization. 8.1 Spatial generalisation Spatial aggregation Spatial aggregation is on the techniques commonly used to anonymise geospatial data. The method helps to mask the exact locations of individuals while still preserving the overall spatial patterns and trends. Spatiall aggregation can take two forms. The first form, which is area aggregation, involves reducing the level of detail by summarising the spatial details into larger spatial units, such as census blocks, zip codes, cities or any other administrative units. The second form is known as point aggregation and involves assigning multiple individual records to one point location. Examples include a population dot map where one dot represents 100 persons. (#fig:geo_data)Spatial aggregation of individual cases using census enumeration units (Paul A. Zandbergen, 2014). Spatial displacement/Adjusting Spatial Coordinates Spatial displacement is another simplest way of anonymising data with exact spatial coordinates by displacing the coordinates in some way. The technique involves shifting spatial data points to different locations within a certain range or distance by for example, adding or subtracting a fixed or random number to both the x-axis and the y-axis. This can preserve the spatial distribution and density of your data while making it difficult to pinpoint the exact location of each point. It involves altering data accuracy to weaken links between the data and the individuals. This would mean that a map feature, for example, a point, is displaced to a new location (d  distance) away from its original location. Spatial displacement should be done with utmost care to ensure that the adjustments do not conflict with the spatial realities, for example by putting a house in the middle of the sea! https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2600804/ 8.2 Attribute anonymisation Attribute anonymisation involves deleting or modifying any attributes or variables that could identify or link to data subjects, such as names, addresses, phone numbers, or email addresses. This technique can protect the personal or confidential information of data subjects while retaining some non-identifying information for analysis. "],["references.html", "Chapter 9 References", " Chapter 9 References Archive, Finnish Social Science Data. 2023. Data Archiving and Access Services in Finland. https://www.fsd.tuni.fi/en/services/data-management-guidelines/anonymisation-and-identifiers/. "]]
