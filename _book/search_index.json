[["index.html", "A Practical Guide to Data Anonymisation Chapter 1 Introduction 1.1 How to cite and license 1.2 Acknowledgements", " A Practical Guide to Data Anonymisation Alice Nikuze, Deniece Nazareth, Minsi Li 2024-11-06 Chapter 1 Introduction In todays data-driven world, privacy concerns have become paramount. With the increasing collection of personal data in research, researchers bear the responsibility of ensuring the protection of the privacy rights of the individuals participating in their studies. In addition, the General Data Protection Regulation (GDPR) in Europe requires researchers affiliated with any institution within the European Economic Area (EEA) to protect the privacy of research participants if they handle personal data in their research. In this context, the more personal data are collected, the greater the need for data de-identification and, eventually, anonymization. This guide provides practical guidance on pseudonymizing and anonymizing personal data in research. It includes hands-on examples of various techniques for different types of research data. Although extensive techniques and examples are given, please note that this guide does not contain every issue related to pseudonymization or anonymisation. As the de-identification of your research data is often complex and a case by case solution. Please advise your privacy contact person for more information. The guide is structured as follows:  In Chapter 2, concepts and principles of data anonymisation are introduced.  In Chapter 3, the principle of data minimisation is introduced.  In Chapter 4, the concepts of data pseudonymisation and anonymisation are explained.  In Chapter 5, the pseudonymization and anonymisation techniques for different types of research data, mainly textual data, numerical data, audio and visual data and spatial data are discussed. Practical examples regarding these types of data are given.  In Chapter 6, the guide concludes with some practical considerations. 1.1 How to cite and license A Practical Guide to Data Anonymization © 2024 by Alice Nikuze, Deniece Nazareth, Minsi Li is licensed under CC BY 4.0. 1.2 Acknowledgements We would like to extend our sincere gratitude to dr. Qian Zhang for her invaluable contribution during the conceptualization phase of this guide. We also wish to express our sincere appreciation to Nestor De la Paz Ruiz for his contribution, whose efforts were instrumental in transforming this guide into a Gitbook. "],["personal_data.html", "Chapter 2 What is personal data?", " Chapter 2 What is personal data? The term Personal data refers to any information that enables you to identify a living person. According to the GDPR, a living person can be identified, directly or indirectly, by means of an identifier such as a name, a citizen identification number, location data, or by other information specific to the physical, physiological, genetic, mental, economic, cultural, or social identity of that living person. Direct identifiers Indirect identifiers Strong indirect identifiers information unique to an individual and sufficient on its own to identify that individual. information that can reveal someones identity when combined with other available information. some identifiers can significantly increase the risk of identifying an individual when combined with other information. Direct identifiers Information unique to an individual can directly identify that person. Strong indirect identifiers Information that can easily identify an individual, such as a rare event, uncommon disease, unique job title, or IP address. Indirect identifiers Information that, when combined with other data, can identify an individual, such as address, age, gender, occupation, location, health records, or ethnic group. It is worth noting that some identifiers are particularly considered strong indirect identifiers because they can significantly increase the risk of identifying an individual when combined with other information. Examples of strong identifiers include a date of birth, an IP address etc. For extensive overview of different types of identifiers, see Table 1. Table 1. Overview of identifiers typically processed in research FSD (2023) "],["minimization.html", "Chapter 3 Principles, concepts and practical considerations 3.1 Data minimization 3.2 Pseudonymisation versus Anonymisation 3.3 Practical Consideration 3.4 How to assess the risks of re-identification 3.5 Steps for anonymisation", " Chapter 3 Principles, concepts and practical considerations 3.1 Data minimization Data minimization is a key principle of data privacy and involves limiting data collection and retention to only what is relevant, necessary, and adequate to accomplish a given purpose. Collecting only the minimum amount of personal data necessary for your research reduces the threat of data breaches and privacy violations, thereby reducing potential consequences for the research participants. In line with this principle, a researcher should only collect and retain the personal data that is required for a research study in mind. Personal data minimization in research can be achieved through: Planning carefully what kind of personal data is necessary for the research purpose. It is advised to carefully plan this early during the research design phase. For instance, you should not ask for the age of a research participant (data subject) if the age effect is not investigated in the research. Collecting aggregated information if detailed information is not necessary. For example, if the age range is sufficient for the analysis, you should not collect the actual age of the participant. Limiting open-ended questions in surveys. Answers to open-ended survey questions provided by respondents occasionally contain personal data about the respondents themselves or other people. Having many open-ended questions in your survey requires more anonymization effort after collecting the data. Instructing research participants sufficiently to avoid unnecessary personal data. In open-ended questions in surveys and during interviews, the participant might mention unnecessary personal information about him/herself or a third person. Adding extra instructions in the survey and reminding the participants not to mention personal data (e.g., other peoples names or addresses) before conducting the interview is well worth the effort. Instructing research participants sufficiently to avoid providing unnecessary personal data. In open-ended questions in surveys and during interviews, the participant might mention unnecessary personal information about him/herself or a third person. Adding extra instructions in the survey and reminding the participants not to mention personal data (e.g., other peoples names or addresses) before conducting the interview is well worth the effort. Adjusting the settings of the data collection tool (e.g., survey tools) to avoid collecting unnecessary personal data. Some survey tools are per default set up to collect personal data such as the location and/or IP address of the user. Always check the settings of the tool you use for data collection. 3.2 Pseudonymisation versus Anonymisation When personal data are necessary and have been collected for research, research participants identities should be protected. Two techniques are used to ensure that research participants remain anonymous and untraceable during and after research- pseudonymisation and anonymization. Pseudonymisation Pseudonymisation is a de-identification process after which personal data can no longer be attributed to a specific data subject without the use of additional information. This process is also referred to as coding. It involves creating two separate files, one linking the personal data to the pseudonyms (made-up values/tokens) and another file which contains only the pseudonyms and the supplied research information. The former file is known as a key file or code list and must be kept separately from the latter file. The key file should be subjected to extra security measures (such as secured storage, password protection and encryption) to ensure that the identities of research participants are protected. Anonymisation Anonymisation is another de-identification process which involves permanently deleting direct and/or indirect identifiers from the data, such that there is no way to link back to individuals (research participants) and the research information they have supplied. In this case, there is no key file that would permit re-identification as this process is irreversible. Pseudonymization is employed to protect the identities of research participants by substituting direct identifiers with pseudonyms. This process is reversible and can still allow re-identification. In contrast, anonymisation involves deleting the identifiers, rendering re-identification impossible, even by researchers themselves. The process is irreversible. 3.3 Practical Consideration Fully anonymized data is not subject to GDPR. Unlike pseudonymized data, fully anonymized data is not subject to GDPR regulations. However, it is important to note that fully anonymized data can be difficult to achieve. Anonymization is not an absolute value, but a spectrum. in the following scenarios, data is not considered as anonymized data: Raw data containing personal data is still present. Key or other information that can be used to re-identify individuals in the dataset still exist. Documenting the anonymization process. s a best practice, the process of anonymization should be thoroughly documented for future reference and research transparency. Such documentation tracks all changes, including removals, replacements, aggregations, or generalizations. It should be stored securely and separately from the data files, as it may contain information that could enable re-identification. Anonymization can negatively impact data utility. anonymization can render data unusable for future analysis or reuse. Data utility refers to the datas ability to address research questions effectively (e.g., if identifying factors essential to the analysis are removed, the data may not support certain types of research). Certain personal details are closely tied to the capacity of addressing research purposes and may not be removed. Therefore, it is crucial to clearly document whether and how anonymization has been performed. Balancing anonymization and data utility. When anonymizing data, its essential to balance the protection of data subjects privacy with the utility of the data. For example, in a study on student performance and family socioeconomic status, identifiers like student names, gender, and age may be removed to protect privacy, while information on grades and family economic conditions should be retained, as these are critical for addressing the research question. Pseudonymization is sometimes preferred over anonymization. Full anonymization may not always be desirable because it reduces the data utility, such as removing context of data. This could be the case in some research. For instance, longitudinal studies benefit from tracking personal data of the same participants over time; thus, pseudonymization is preferred over anonymization. Assessing re-identification risks. Anonymized data is data from which personal information has been removed to prevent identifying individuals. However, there is are always a risks of re-identification through singling out, inference, or linking with other data or techniques. Therefore, it is recommended to assess re-identification risks carefully before sharing data. Based on this assessment, researchers can also determine the appropriate scope of data recipients. 3.4 How to assess the risks of re-identification Re-identification risk assessment is the process of evaluating the likelihood that anonymized data could still reveal individual identities through singling out, linking, and inference ICO (2021). Singling Out: Can an individual be isolated from the dataset? Unique Data Points: To assess re-identification risk, check if any data points are unique in combination with other attributes. If a category created by any two attributes (e.g., age and occupation) has only one data point, that data point is unique and poses a re-identification risk. Aim to have at least three data points in each unique category to reduce this risk. Linking: Can information within the dataset be combined with external data to identify an individual? Inference: Can details about an individual be inferred, guessed, or predicted based on patterns in the dataset or previous knowledge? Sample vs. Population Uniqueness: uniqueness in a dataset sample can still mean uniqueness in the broader population and that an increase re-identification risk. For example, a rare disease patient or a specialized surgeon might be unique both in the dataset and in real life, making them identifiable. External Databases: Consider if other datasets or personal knowledge could identify individuals already exist. Existing re-identification technology and skills: Assess if techniques and skills exist that could reverse anonymization or link data back to individuals. Sharing Scope: Publicly shared data poses a higher re-identification risk than data shared with a limited group. 3.5 Steps for anonymisation The setps for anonymization can be found in the table below UK_Data_Service (2024),PDPC (2022). Table 3.1: Table 3.2: Steps for anonymisation Steps for anonymization    How to  Questions to consider  Know your data You can start with identifying potential identifiers in the data, for example direct and indirect identifiers. For an overview of identifiers, please see chapter 2. What kind of data do you want to anonymize or pseudonymize, such as textual, numerical, audio, video data? Which identifiers exist, direct, strong indirect, or indirect identifiers? 2.De-identify your data by applying anonymization or pseudonymization techniques You can use different techniques to anonymize or pseudonymize the identifiers in your data. For an overview of different techniques for various research types, please see chapter 4. When applying anonymization techniques, please be aware that it can have an impact on the data utility as you are removing or modifying data values. Data utility related to attributes that researchers are interested in. How can you retain the data utility but still modify the data to prevent identification? 3.Compute risk Review the data and confirm no personal data or risk of re-identificatin remain. Any remaining information in the dataset still sensitive, or unique? To measure uniqueness of a data point, identify the number of data points in each subcategory of the dataset. If there is only one data point in a category, that value is nique, indicating a high risk of re-identification. It is ideal to strive for at least 3 data points in one distinct combination of any two remaining (in)direct identifiers. Manage risk Documentation of the de-identification to ensure transparency Who are the recipients of the data? Are they a specific group or the general public? The broader the range of data recipients, the more stringent the anonymization measures should be.  Can any external datasets be linked to yours to potentially re-identify data subjects? For instance, isolated incidences can be linked to the dataset to single out or infer to data subject. For instance, the first person in the moon, or a rare disease in a neighbourhood. Any techniques can enable identification? "],["textual-data.html", "Chapter 4 Textual data 4.1 Generalisation: Replace or aggregate 4.2 Distort", " Chapter 4 Textual data Textual data refers to any text-based content such as transcripts of interviews, workshops and focus group discussions, open-ended questions in surveys, observational notes, meeting notes, etc. This data type can be de-identified by generalizing the identifying information, distorting or deleting the identifiers such as research participants names, gender, age, income, places and institutions names, addresses (physical location, email and IP), telephone numbers and any other sensitive information. The following techniques are commonly used to pseudonymize or anonymize textual data. 4.1 Generalisation: Replace or aggregate Generalization involves reducing detailed information or the precision of the information in a way that potentially disclosive information is replaced or aggregated. This approach mainly involves replacing or aggregating identifiers with vague descriptors, such as replacing the actual names of individuals with aliases or with other aggregated information. 4.2 Distort In certain cases, instead of generalizing crucial information needed to understand the context and content, its possible to distort the information by changing other identifiers. For example, if you have interviewed someone who participated in a high-level sports competition, and if that information is of importance in research, then you may change other values. You could change the years when the competition took place, the region (place, country) or even the gender of the person if this is not crucial information. 4.2.1 Suppression: Delete If the identifying information cannot be replaced or generalized, the entire variable or text may need to be deleted and explicitly marked as such by using [brackets]. 4.2.2 Masking Masking textual data involves replacing letters or symbols (punctuation) in identifying information entirely or partially with a special symbol (such as * or x). It is commonly used for identifiers such as email addresses, names of locations, etc. This technique is more suitable for structured tabular data, meaning that data is stored in the form of columns and rows. For more inspiration on how to anonymize textual data, please consult this illustrative example provided by CESSDA, which demonstrates the process of anonymizing an interview script. Tools Masking can be performed through manipulation in character data and natural language processing in R or Python. Some examples can be found in the Mask attributes section under Numerical Data in this guide. "],["numerical-data.html", "Chapter 5 Numerical data 5.1 Generalisation 5.2 Suppression 5.3 Swapping 5.4 Masking", " Chapter 5 Numerical data Numerical data is data in the form of numbers and is often displayed in a table with rows and columns. The techniques commonly used to anonymise numerical data include: 5.1 Generalisation Generalisation techniques reduce the granularity of the attributes/records in the data. It can be performed by Categorising personal identifiers. For example, age is replaced by an age category or range. Top and bottom coding of the upper or lower ranges. Very high and low values are grouped into categories to minimize identifiability due to outliers. For example, age records above a certain upper and lower limit are classified as groups to avoid recognition of exceptionally older or younger individuals while preserving actual ages for the rest of the population within the wider group researched. A top code of  X or more could be applied to avoid identifying older subjects. Collapsing and/or combining variables. Merging data recorded in two or more variables into a single category. This is particularly useful if the initial data collection creates several categories with very few subjects in each. Perturbation can be used where small changes in value are acceptable. This technique involves rounding, adding noise, or replacing real values with simulation values. It should not be used when data accuracy is critical. The following section demonstrates examples of rounding and adding noise techniques with practical examples. Rounding It returns a number rounded to a base number to prevent exact matching with external data sources (https://sdcpractice.readthedocs.io/en/latest/anon_methods.html#special-case-census-data). It can be used to deal with data like age, height, weight, or house number. Examples of rounding is demonstrated with tools, Excel, R, or Python. Noise addition This technique adds or subtracts the original values with a random number. Larger random numbers result in higher levels of noise. Note that the results of noise addition are irreversible because each modification introduces randomness to the original values. This technique can be used to few values, such as outliers, or to entire dataset. When handling data with continuous value, the distribution of continuous data should be preserved to maintain more information in the datasets. Examples can be found in the table below. 5.2 Suppression Suppression involves deleting the identifying information from the data. Some attributes (variables) or records (observations) can be removed in certain cases to make the identifier is not unique anymore. 5.3 Swapping This technique is also known as shuffling and permutation. When each data subjects has attributes which are stored in the columns in a spreadsheet, swap the attributes among two random data subjects till exhaust all data subjects in the dataset. In this way, the distribution of attributes would not be changes, while each data subjects attributes are changed. For example, when collecting each data subjects email address and IP address, swap each subjects IP address would reduce the chances of identifying one data subject with their both email address and IP address. 5.4 Masking The same way letters in textual data are replaced, numbers can be entirely or partially replaced with a special symbol (such as * or x). See the table below for examples. "],["audio-visual-data.html", "Chapter 6 Audio-Visual data 6.1 Voice transformation/distortion 6.2 Blurring, pixelation or obscuring 6.3 Mute or bleep out the identifying information", " Chapter 6 Audio-Visual data Audio-visual data includes various forms of multimedia content, such as videos, movies, and audio recordings, including voices and visual components. In research, these forms of data capture interviews, workshops and any other form of communication with research participants involving their voices and/or images. Anonymizing these types of data involves modifying the audio, video or images, which will be introduced in this section. Keep in mind that these techniques can be time-consuming or expensive to use. Icons made by Icon mania from www.flaticon.com 6.1 Voice transformation/distortion This technique involves disguising voices such as altering the pitch in a recording. Keep in mind that transforming or distorting the voice can reduce the usefulness of the data. Therefore, the decision of modifying sounds should be made based on your research objectives. 6.2 Blurring, pixelation or obscuring Blurring by pixelating specific regions of a video image or a picture, such as faces, can effectively anonymize individuals. This technique involves reducing the level of detail in those areas, making it harder to identify the person. In addition, you can also obscure the face of a person. See Image XX for an example of pixelating a face. Simpel distortion of the audio or imagery can only prevent idetnfication based on the speakers voice or iamge but it cannot remove other idetnfiying information that might exist in the recoding, such as speaking patterns or the mentioned personal information. 6.3 Mute or bleep out the identifying information In audio or video recordings, you can also mute or bleep out identifying information to anonymize the audio-visual data. For example, you can mute or bleep out identifiers such as names, places or other information. Please see image XX below where the personal name has been muted in the audio recording. Software for audio-visual data  For audio data, audio editing software such as Audacity can be used to transform or distort the voice or bleep out personal information.  Different video editing software such as Adobe Premiere can be used to blur or pixelate video recordings or transform, distort or bleep out information in the audio recording.  For images, image editor tools such as Photoshop and Paint can be used to blur, pixelate or obscure faces or personal information in pictures and images. "],["geospatial-data.html", "Chapter 7 Geospatial data 7.1 Spatial generalisation 7.2 Attribute anonymisation", " Chapter 7 Geospatial data Geospatial data refers to data that is associated with specific geographic locations. Spatial data are used in research for analysis, visualization, and understanding of relationships and patterns within a geographic context. This section presents some of the techniques used to de-identify spatial data. The existing anonymisation techniques fall into two categories of generalization and randomization. 7.1 Spatial generalisation Spatial aggregation Spatial aggregation is on the techniques commonly used to anonymise geospatial data. The method helps to mask the exact locations of individuals while still preserving the overall spatial patterns and trends. Spatiall aggregation can take two forms. The first form, which is area aggregation, involves reducing the level of detail by summarising the spatial details into larger spatial units, such as census blocks, zip codes, cities or any other administrative units. The second form is known as point aggregation and involves assigning multiple individual records to one point location. Examples include a population dot map where one dot represents 100 persons. (#fig:geo_data)Spatial aggregation of individual cases using census enumeration units (Zandbergen, 2014). Spatial displacement/Adjusting Spatial Coordinates Spatial displacement is another simplest way of anonymising data with exact spatial coordinates by displacing the coordinates in some way. The technique involves shifting spatial data points to different locations within a certain range or distance by for example, adding or subtracting a fixed or random number to both the x-axis and the y-axis. This can preserve the spatial distribution and density of your data while making it difficult to pinpoint the exact location of each point. It involves altering data accuracy to weaken links between the data and the individuals. This would mean that a map feature, for example, a point, is displaced to a new location (d  distance) away from its original location. Spatial displacement should be done with utmost care to ensure that the adjustments do not conflict with the spatial realities, for example by putting a house in the middle of the sea! 7.2 Attribute anonymisation Attribute anonymisation involves deleting or modifying any attributes or variables that could identify or link to data subjects, such as names, addresses, phone numbers, or email addresses. This technique can protect the personal or confidential information of data subjects while retaining some non-identifying information for analysis. "],["references.html", "Chapter 8 References", " Chapter 8 References FSD, Finnish Social Science Data Archive. 2023. Data Archiving and Access Services in Finland. https://www.fsd.tuni.fi/en/services/data-management-guidelines/anonymisation-and-identifiers/. ICO, Information Commissioners Office. 2021. Draft Anonymisation,pseudonymisation and Privacy Enhancing Technologies Guidance. The Information Commissioners Office. https://ico.org.uk/media/about-the-ico/documents/4018606/chapter-2-anonymisation-draft.pdf. PDPC, Personal data protection commission. 2022. Guide to Basic Anonymization. Personal Data Protection Commission. https://www.pdpc.gov.sg/-/media/files/pdpc/pdf-files/advisory-guidelines/guide-to-basic-anonymisation-(updated-24-july-2024).pdf. UK_Data_Service. 2024. Anonymisation Step-by-Step. UK Data Service. https://ukdataservice.ac.uk/learning-hub/research-data-management/anonymisation/anonymisation-step-by-step/. "]]
